{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1cf924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages are installed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def ensure_package(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for package in [\"pandas\"]:\n",
    "    ensure_package(package)\n",
    "\n",
    "print(\"All required packages are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa3de049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16515def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration complete\n",
      "Base directory: /workspaces/crash-data\n",
      "Raw data directory: /workspaces/crash-data/data/raw\n",
      "Output directory: /workspaces/crash-data/analysis_outputs\n"
     ]
    }
   ],
   "source": [
    "# Data source URLs organized by year and type\n",
    "from pathlib import Path\n",
    "CRASHES = {\n",
    "    2021: \"https://data.ca.gov/datastore/dump/d08692e2-6d36-487e-bca0-28cd127a626f?format=csv\",\n",
    "    2022: \"https://data.ca.gov/datastore/dump/7828780b-117b-455e-9275-986ad3ffde50?format=csv\",\n",
    "    2023: \"https://data.ca.gov/datastore/dump/436642c0-cd04-4a4c-b45e-564b66437476?format=csv\",\n",
    "    2024: \"https://data.ca.gov/datastore/dump/f775df59-b89b-4f82-bd3d-8807fa3a22a0?format=csv\",\n",
    "    2025: \"https://data.ca.gov/datastore/dump/9f4fc839-122d-4595-a146-43bc4ed16f46?format=csv\",\n",
    "}\n",
    "PARTIES = {\n",
    "    2021: \"https://data.ca.gov/datastore/dump/754fe00c-f3bf-4f2f-80d0-ed4aa7b89b77?format=csv\",\n",
    "    2022: \"https://data.ca.gov/datastore/dump/9ef51178-51cb-4939-9344-2d0907740580?format=csv\",\n",
    "    2023: \"https://data.ca.gov/datastore/dump/84376be5-548b-44e3-8ebc-73e8a2ca9945?format=csv\",\n",
    "    2024: \"https://data.ca.gov/datastore/dump/93892d36-017b-4a2a-bc0b-f1f385060b96?format=csv\",\n",
    "    2025: \"https://data.ca.gov/datastore/dump/a2676918-a825-4b77-8e5c-6eadb38d6b1a?format=csv\",\n",
    "}\n",
    "INJURED_WITNESSES = {\n",
    "    2021: \"https://data.ca.gov/datastore/dump/616a9850-27cb-4012-b6e7-90a2e495900a?format=csv\",\n",
    "    2022: \"https://data.ca.gov/datastore/dump/2d9e8bef-d5a2-402e-82eb-6386ad4d09f7?format=csv\",\n",
    "    2023: \"https://data.ca.gov/datastore/dump/1dfc36fa-a5dd-4616-b9b0-ff55699e299a?format=csv\",\n",
    "    2024: \"https://data.ca.gov/datastore/dump/a36a0078-d7e1-4244-8337-0a59433c9b84?format=csv\",\n",
    "    2025: \"https://data.ca.gov/datastore/dump/10184ea3-7411-42d8-87a6-17039b58f04b?format=csv\",\n",
    "}\n",
    "YEARS = [2021, 2022, 2023, 2024, 2025]\n",
    "# Setup directories - portable across systems\n",
    "BASE_DIR = Path.cwd()\n",
    "RAW_DIR = BASE_DIR / \"data\" / \"raw\"\n",
    "OUTPUT_DIR = BASE_DIR / \"analysis_outputs\"\n",
    "# Create directories if they don't exist\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Configuration complete\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Raw data directory: {RAW_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46198747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data download...\n",
      "\n",
      "--- Year 2021 ---\n",
      "âœ“ exists: crashes_2021.csv\n",
      "âœ“ exists: parties_2021.csv\n",
      "âœ“ exists: injured_witnesses_2021.csv\n",
      "\n",
      "--- Year 2022 ---\n",
      "âœ“ exists: crashes_2022.csv\n",
      "âœ“ exists: parties_2022.csv\n",
      "âœ“ exists: injured_witnesses_2022.csv\n",
      "\n",
      "--- Year 2023 ---\n",
      "âœ“ exists: crashes_2023.csv\n",
      "âœ“ exists: parties_2023.csv\n",
      "âœ“ exists: injured_witnesses_2023.csv\n",
      "\n",
      "--- Year 2024 ---\n",
      "âœ“ exists: crashes_2024.csv\n",
      "âœ“ exists: parties_2024.csv\n",
      "âœ“ exists: injured_witnesses_2024.csv\n",
      "\n",
      "--- Year 2025 ---\n",
      "âœ“ exists: crashes_2025.csv\n",
      "âœ“ exists: parties_2025.csv\n",
      "âœ“ exists: injured_witnesses_2025.csv\n",
      "\n",
      " All downloads complete\n"
     ]
    }
   ],
   "source": [
    "def download_if_missing(url: str, dest: Path) -> None:\n",
    "    \"\"\"Download file from URL if it doesn't exist locally or is empty.\"\"\"\n",
    "    if dest.exists() and dest.stat().st_size > 0:\n",
    "        print(f\"âœ“ exists: {dest.name}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"â†“ downloading: {dest.name}\")\n",
    "    tmp = dest.with_suffix(dest.suffix + \".part\")\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, tmp)\n",
    "        tmp.replace(dest)\n",
    "        print(f\"âœ“ saved: {dest.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— failed to download {dest.name}: {e}\")\n",
    "        if tmp.exists():\n",
    "            tmp.unlink()\n",
    "        raise\n",
    "    finally:\n",
    "        if tmp.exists():\n",
    "            tmp.unlink(missing_ok=True)\n",
    "def download_all_data() -> None:\n",
    "    \"\"\"Download all required data files.\"\"\"\n",
    "    print(\"Starting data download...\")\n",
    "    \n",
    "    for year in YEARS:\n",
    "        print(f\"\\n--- Year {year} ---\")\n",
    "        download_if_missing(CRASHES[year], RAW_DIR / f\"crashes_{year}.csv\")\n",
    "        download_if_missing(PARTIES[year], RAW_DIR / f\"parties_{year}.csv\")\n",
    "        download_if_missing(INJURED_WITNESSES[year], RAW_DIR / f\"injured_witnesses_{year}.csv\")\n",
    "    \n",
    "    print(\"\\n All downloads complete\")\n",
    "# Run the download\n",
    "download_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd4e43c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "def norm(column_name: str) -> str:\n",
    "    \"\"\"Normalize column names for consistent matching.\"\"\"\n",
    "    return \"\".join(ch for ch in str(column_name).strip().lower() if ch.isalnum())\n",
    "def build_address(row: pd.Series) -> str:\n",
    "    \"\"\"Build a readable address from crash location components.\"\"\"\n",
    "    primary = str(row.get(\"PrimaryRoad\", \"\")).strip()\n",
    "    secondary = str(row.get(\"SecondaryRoad\", \"\")).strip()\n",
    "    sec_direction = str(row.get(\"SecondaryDirection\", \"\")).strip()\n",
    "    sec_distance = str(row.get(\"SecondaryDistance\", \"\")).strip()\n",
    "    if primary and secondary and secondary.lower() != \"nan\":\n",
    "        return f\"{primary} & {secondary}\"\n",
    "    if primary:\n",
    "        if (\n",
    "            sec_distance\n",
    "            and sec_distance.lower() != \"nan\"\n",
    "            and sec_direction\n",
    "            and sec_direction.lower() != \"nan\"\n",
    "        ):\n",
    "            return f\"{sec_direction} {sec_distance} from {primary}\"\n",
    "        return primary\n",
    "    return \"\"\n",
    "def load_crashes_data(year: int) -> pd.DataFrame:\n",
    "    \"\"\"Load and return crashes data for a given year.\"\"\"\n",
    "    crashes_path = RAW_DIR / f\"crashes_{year}.csv\"\n",
    "    if not crashes_path.exists():\n",
    "        raise FileNotFoundError(f\"Crashes data for {year} not found: {crashes_path}\")\n",
    "    \n",
    "    return pd.read_csv(crashes_path, low_memory=False)\n",
    "def load_parties_data_chunked(year: int, chunk_size: int = 200_000):\n",
    "    \"\"\"Load parties data in chunks for memory efficiency.\"\"\"\n",
    "    parties_path = RAW_DIR / f\"parties_{year}.csv\"\n",
    "    if not parties_path.exists():\n",
    "        raise FileNotFoundError(f\"Parties data for {year} not found: {parties_path}\")\n",
    "    \n",
    "    return pd.read_csv(\n",
    "        parties_path,\n",
    "        chunksize=chunk_size,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",\n",
    "    )\n",
    "print(\"Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "857d1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SF Crash Analysis...\n",
      "\n",
      "--- Processing 2021 ---\n",
      "  SF crashes: 5,767\n",
      "    Processing chunk 5...\n",
      "  Bicyclist parties: 426\n",
      "  Unique bike crashes: 418\n",
      "\n",
      "--- Processing 2022 ---\n",
      "  SF crashes: 5,769\n",
      "  Bicyclist parties: 407\n",
      "  Unique bike crashes: 400\n",
      "\n",
      "--- Processing 2023 ---\n",
      "  SF crashes: 5,967\n",
      "    Processing chunk 5...\n",
      "  Bicyclist parties: 405\n",
      "  Unique bike crashes: 393\n",
      "\n",
      "--- Processing 2024 ---\n",
      "  SF crashes: 6,223\n",
      "    Processing chunk 5...\n",
      "  Bicyclist parties: 511\n",
      "  Unique bike crashes: 497\n",
      "\n",
      "--- Processing 2025 ---\n",
      "  SF crashes: 6,094\n",
      "    Processing chunk 5...\n",
      "  Bicyclist parties: 998\n",
      "  Unique bike crashes: 489\n",
      "\n",
      " Processing age frequency data...\n",
      " Analysis complete!\n",
      "\n",
      "âœ… Saved visualization summaries:\n",
      " - /workspaces/crash-data/analysis_outputs/pedestrian_crash_summary_table.csv\n",
      " - /workspaces/crash-data/analysis_outputs/pedestrian_crash_summary_table_by_year.csv\n"
     ]
    }
   ],
   "source": [
    "def run_analysis() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run the complete SF crash analysis.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (age_frequency, nonblank_age_frequency, bicyclist_counts, bike_locations)\n",
    "    \"\"\"\n",
    "    print(\"Starting SF Crash Analysis...\")\n",
    "    \n",
    "    all_non_driver_ages = []\n",
    "    yearly_bicyclist_counts = []\n",
    "    bike_location_frames = []\n",
    "    for year in YEARS:\n",
    "        print(f\"\\n--- Processing {year} ---\")\n",
    "        \n",
    "        # Load crashes data\n",
    "        crashes = load_crashes_data(year)\n",
    "        crash_cols = {norm(c): c for c in crashes.columns}\n",
    "        # Extract required column names\n",
    "        col_collision = crash_cols.get(\"collisionid\")\n",
    "        col_city = crash_cols.get(\"cityname\")\n",
    "        col_primary = crash_cols.get(\"primaryroad\")\n",
    "        col_secondary = crash_cols.get(\"secondaryroad\")\n",
    "        col_secdir = crash_cols.get(\"secondarydirection\")\n",
    "        col_secdist = crash_cols.get(\"secondarydistance\")\n",
    "        col_lat = crash_cols.get(\"latitude\")\n",
    "        col_lon = crash_cols.get(\"longitude\")\n",
    "        col_dt = crash_cols.get(\"crashdatetime\")\n",
    "        if col_collision is None or col_city is None:\n",
    "            raise ValueError(f\"Required crash columns missing in {year} data\")\n",
    "        # Filter for San Francisco crashes\n",
    "        sf_crashes = crashes[\n",
    "            crashes[col_city].astype(str).str.strip().str.upper().eq(\"SAN FRANCISCO\")\n",
    "        ].copy()\n",
    "        sf_crashes[col_collision] = sf_crashes[col_collision].astype(str).str.strip()\n",
    "        sf_collision_ids = set(sf_crashes[col_collision].dropna().tolist())\n",
    "        \n",
    "        print(f\"  SF crashes: {len(sf_collision_ids):,}\")\n",
    "        # Process parties data in chunks\n",
    "        chunk_iter = load_parties_data_chunked(year)\n",
    "        \n",
    "        non_driver_age_rows = []\n",
    "        bicyclist_party_count = 0\n",
    "        bike_collision_ids = set()\n",
    "        sf_party_row_count = 0\n",
    "        for chunk_num, chunk in enumerate(chunk_iter, 1):\n",
    "            if chunk_num % 5 == 0:\n",
    "                print(f\"    Processing chunk {chunk_num}...\")\n",
    "                \n",
    "            party_cols = {norm(c): c for c in chunk.columns}\n",
    "            p_col_collision = party_cols.get(\"collisionid\")\n",
    "            p_col_partytype = party_cols.get(\"partytype\")\n",
    "            p_col_age = party_cols.get(\"statedage\")\n",
    "            if p_col_collision is None or p_col_partytype is None:\n",
    "                raise ValueError(f\"Required party columns missing in {year} data\")\n",
    "            # Filter for SF parties\n",
    "            chunk[p_col_collision] = chunk[p_col_collision].astype(str).str.strip()\n",
    "            sf_parties = chunk[chunk[p_col_collision].isin(sf_collision_ids)].copy()\n",
    "            if sf_parties.empty:\n",
    "                continue\n",
    "            sf_party_row_count += len(sf_parties)\n",
    "            party_type_upper = (\n",
    "                sf_parties[p_col_partytype].astype(str).str.strip().str.upper()\n",
    "            )\n",
    "            # Collect non-driver ages\n",
    "            non_driver_mask = ~party_type_upper.eq(\"DRIVER\")\n",
    "            if p_col_age is not None:\n",
    "                ages = sf_parties.loc[non_driver_mask, [p_col_age]].copy()\n",
    "                ages.columns = [\"StatedAge\"]\n",
    "                non_driver_age_rows.append(ages)\n",
    "            # Count bicyclists\n",
    "            bike_mask = party_type_upper.str.contains(\"BICYCL\", na=False)\n",
    "            bicyclist_party_count += int(bike_mask.sum())\n",
    "            if bike_mask.any():\n",
    "                bike_collision_ids.update(\n",
    "                    sf_parties.loc[bike_mask, p_col_collision]\n",
    "                    .dropna()\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .tolist()\n",
    "                )\n",
    "        # Store non-driver ages for this year\n",
    "        if non_driver_age_rows:\n",
    "            all_non_driver_ages.append(pd.concat(non_driver_age_rows, ignore_index=True))\n",
    "        # Store yearly bicyclist counts\n",
    "        yearly_bicyclist_counts.append(\n",
    "            {\n",
    "                \"Year\": year,\n",
    "                \"BicyclistPartyCount\": bicyclist_party_count,\n",
    "                \"UniqueBikeCrashCount\": len(bike_collision_ids),\n",
    "                \"SFCollisionCount\": len(sf_collision_ids),\n",
    "                \"SFPartyRowCount\": sf_party_row_count,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"  Bicyclist parties: {bicyclist_party_count:,}\")\n",
    "        print(f\"  Unique bike crashes: {len(bike_collision_ids):,}\")\n",
    "        # Extract bike crash locations\n",
    "        if bike_collision_ids:\n",
    "            location_cols = [\n",
    "                c\n",
    "                for c in [\n",
    "                    col_collision,\n",
    "                    col_primary,\n",
    "                    col_secondary,\n",
    "                    col_secdir,\n",
    "                    col_secdist,\n",
    "                    col_lat,\n",
    "                    col_lon,\n",
    "                    col_dt,\n",
    "                ]\n",
    "                if c is not None\n",
    "            ]\n",
    "            bike_locations = sf_crashes[\n",
    "                sf_crashes[col_collision].astype(str).str.strip().isin(bike_collision_ids)\n",
    "            ][location_cols].copy()\n",
    "            bike_locations[\"Year\"] = year\n",
    "            # Standardize column names\n",
    "            rename_map = {\n",
    "                col_collision: \"CollisionId\",\n",
    "                col_primary: \"PrimaryRoad\",\n",
    "                col_secondary: \"SecondaryRoad\",\n",
    "                col_secdir: \"SecondaryDirection\",\n",
    "                col_secdist: \"SecondaryDistance\",\n",
    "                col_lat: \"Latitude\",\n",
    "                col_lon: \"Longitude\",\n",
    "                col_dt: \"CrashDateTime\",\n",
    "            }\n",
    "            bike_locations = bike_locations.rename(\n",
    "                columns={k: v for k, v in rename_map.items() if k in bike_locations.columns}\n",
    "            )\n",
    "            # Build addresses\n",
    "            bike_locations[\"Address\"] = bike_locations.apply(build_address, axis=1)\n",
    "            keep_cols = [\n",
    "                c\n",
    "                for c in [\n",
    "                    \"Year\",\n",
    "                    \"CollisionId\",\n",
    "                    \"Address\",\n",
    "                    \"PrimaryRoad\",\n",
    "                    \"SecondaryRoad\",\n",
    "                    \"Latitude\",\n",
    "                    \"Longitude\",\n",
    "                    \"CrashDateTime\",\n",
    "                ]\n",
    "                if c in bike_locations.columns\n",
    "            ]\n",
    "            bike_location_frames.append(\n",
    "                bike_locations[keep_cols].drop_duplicates(subset=[\"CollisionId\"])\n",
    "            )\n",
    "    # Process age frequency data\n",
    "    if all_non_driver_ages:\n",
    "        print(\"\\n Processing age frequency data...\")\n",
    "        ages = pd.concat(all_non_driver_ages, ignore_index=True)\n",
    "        ages[\"StatedAge\"] = ages[\"StatedAge\"].astype(str).str.strip()\n",
    "        ages.loc[\n",
    "            ages[\"StatedAge\"].isin([\"\", \"nan\", \"None\"]), \"StatedAge\"\n",
    "        ] = \"(blank)\"\n",
    "        age_frequency = (\n",
    "            ages.groupby(\"StatedAge\", dropna=False)\n",
    "            .size()\n",
    "            .reset_index(name=\"Frequency\")\n",
    "        )\n",
    "        # Clean up decimal formatting\n",
    "        age_frequency[\"StatedAge\"] = age_frequency[\"StatedAge\"].apply(\n",
    "            lambda v: str(v)[:-2]\n",
    "            if str(v).endswith(\".0\") and str(v)[:-2].replace(\"-\", \"\").isdigit()\n",
    "            else str(v)\n",
    "        )\n",
    "        age_frequency = (\n",
    "            age_frequency.groupby(\"StatedAge\", as_index=False)[\"Frequency\"]\n",
    "            .sum()\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        # Sort by numeric age where possible\n",
    "        age_frequency[\"_age_num\"] = pd.to_numeric(\n",
    "            age_frequency[\"StatedAge\"], errors=\"coerce\"\n",
    "        )\n",
    "        age_frequency = (\n",
    "            age_frequency.sort_values(\n",
    "                [\"_age_num\", \"StatedAge\"], na_position=\"last\"\n",
    "            )\n",
    "            .drop(columns=[\"_age_num\"])\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        nonblank_age_frequency = age_frequency[\n",
    "            ~age_frequency[\"StatedAge\"].isin([\"(blank)\", \"\", \"nan\", \"None\"])\n",
    "        ].copy()\n",
    "    else:\n",
    "        age_frequency = pd.DataFrame(columns=[\"StatedAge\", \"Frequency\"])\n",
    "        nonblank_age_frequency = age_frequency.copy()\n",
    "    # Process bicyclist counts\n",
    "    bicyclist_counts = pd.DataFrame(yearly_bicyclist_counts).sort_values(\n",
    "        \"Year\"\n",
    "    ).reset_index(drop=True)\n",
    "    # Process bike locations\n",
    "    if bike_location_frames:\n",
    "        bike_locations_final = pd.concat(bike_location_frames, ignore_index=True)\n",
    "        bike_locations_final = bike_locations_final.sort_values(\n",
    "            [\"Year\", \"CollisionId\"]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        bike_locations_final = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"Year\",\n",
    "                \"CollisionId\",\n",
    "                \"Address\",\n",
    "                \"PrimaryRoad\",\n",
    "                \"SecondaryRoad\",\n",
    "                \"Latitude\",\n",
    "                \"Longitude\",\n",
    "                \"CrashDateTime\",\n",
    "            ]\n",
    "        )\n",
    "    print(\" Analysis complete!\")\n",
    "    # --- Save pedestrian summary CSVs for visualization ---\n",
    "    OUT_DIR = OUTPUT_DIR  # reuse previous variable if defined\n",
    "    OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    # Create overall and year-level summary versions compatible with viz section\n",
    "    overall_summary = age_freq_nonblank.copy()\n",
    "    overall_path = OUT_DIR / \"pedestrian_crash_summary_table.csv\"\n",
    "    overall_summary.to_csv(overall_path, index=False)\n",
    "\n",
    "    yearly_summary_data = []\n",
    "    for y in YEARS:\n",
    "        subset = bike_counts[bike_counts[\"Year\"] == y].copy()\n",
    "        subset[\"source_year\"] = y\n",
    "        subset[\"age_group\"] = \"(not computed)\"\n",
    "        subset[\"sex\"] = \"(not computed)\"\n",
    "        subset[\"severity\"] = \"(not computed)\"\n",
    "        subset[\"crash_count\"] = subset[\"BicyclistPartyCount\"]\n",
    "        yearly_summary_data.append(subset[[\"source_year\", \"age_group\", \"sex\", \"severity\", \"crash_count\"]])\n",
    "    summary_by_year = pd.concat(yearly_summary_data, ignore_index=True)\n",
    "    yearly_path = OUT_DIR / \"pedestrian_crash_summary_table_by_year.csv\"\n",
    "    summary_by_year.to_csv(yearly_path, index=False)\n",
    "\n",
    "    print(\"\\n Saved visualization summaries:\")\n",
    "    print(\" -\", overall_path)\n",
    "    print(\" -\", yearly_path)\n",
    "\n",
    "    return age_frequency, nonblank_age_frequency, bicyclist_counts, bike_locations_final\n",
    "# Run the analysis\n",
    "age_freq, age_freq_nonblank, bike_counts, bike_locations = run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ad2341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files saved:\n",
      "  â€¢ /workspaces/crash-data/analysis_outputs/sf_non_driver_stated_age_frequency_2021_2025.csv\n",
      "  â€¢ /workspaces/crash-data/analysis_outputs/sf_non_driver_stated_age_frequency_nonblank_2021_2025.csv\n",
      "  â€¢ /workspaces/crash-data/analysis_outputs/sf_bicyclist_involved_counts_by_year_2021_2025.csv\n",
      "  â€¢ /workspaces/crash-data/analysis_outputs/sf_bicycle_crash_locations_2021_2025.csv\n",
      "\n",
      " Summary Statistics:\n",
      "  â€¢ Total non-driver age records: 15,426\n",
      "  â€¢ Non-blank age records: 112\n",
      "  â€¢ Total bicycle crash locations: 2,197\n",
      "\n",
      " Yearly Bicyclist Involvement:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>BicyclistPartyCount</th>\n",
       "      <th>UniqueBikeCrashCount</th>\n",
       "      <th>SFCollisionCount</th>\n",
       "      <th>SFPartyRowCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>426</td>\n",
       "      <td>418</td>\n",
       "      <td>5767</td>\n",
       "      <td>11963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>407</td>\n",
       "      <td>400</td>\n",
       "      <td>5769</td>\n",
       "      <td>11965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>405</td>\n",
       "      <td>393</td>\n",
       "      <td>5967</td>\n",
       "      <td>12450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>511</td>\n",
       "      <td>497</td>\n",
       "      <td>6223</td>\n",
       "      <td>12824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>998</td>\n",
       "      <td>489</td>\n",
       "      <td>6094</td>\n",
       "      <td>25019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  BicyclistPartyCount  UniqueBikeCrashCount  SFCollisionCount  \\\n",
       "0  2021                  426                   418              5767   \n",
       "1  2022                  407                   400              5769   \n",
       "2  2023                  405                   393              5967   \n",
       "3  2024                  511                   497              6223   \n",
       "4  2025                  998                   489              6094   \n",
       "\n",
       "   SFPartyRowCount  \n",
       "0            11963  \n",
       "1            11965  \n",
       "2            12450  \n",
       "3            12824  \n",
       "4            25019  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¥ Top 10 Non-Driver Ages (Non-blank):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StatedAge</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StatedAge  Frequency\n",
       "0        11          1\n",
       "1        12          2\n",
       "2        18          1\n",
       "3        19          1\n",
       "4        20          2\n",
       "5        22          2\n",
       "6        24          1\n",
       "7        25          7\n",
       "8        26          5\n",
       "9        27          2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_results_and_display_summary(\n",
    "    age_frequency: pd.DataFrame,\n",
    "    nonblank_age_frequency: pd.DataFrame,\n",
    "    bicyclist_counts: pd.DataFrame,\n",
    "    bike_locations: pd.DataFrame\n",
    ") -> None:\n",
    "    \"\"\"Save analysis results to CSV files and display summary.\"\"\"\n",
    "    \n",
    "    # Define output file paths\n",
    "    age_path = OUTPUT_DIR / \"sf_non_driver_stated_age_frequency_2021_2025.csv\"\n",
    "    age_nonblank_path = OUTPUT_DIR / \"sf_non_driver_stated_age_frequency_nonblank_2021_2025.csv\"\n",
    "    counts_path = OUTPUT_DIR / \"sf_bicyclist_involved_counts_by_year_2021_2025.csv\"\n",
    "    bike_locations_path = OUTPUT_DIR / \"sf_bicycle_crash_locations_2021_2025.csv\"\n",
    "    # Save to CSV files\n",
    "    age_frequency.to_csv(age_path, index=False)\n",
    "    nonblank_age_frequency.to_csv(age_nonblank_path, index=False)\n",
    "    bicyclist_counts.to_csv(counts_path, index=False)\n",
    "    bike_locations.to_csv(bike_locations_path, index=False)\n",
    "    print(\"Output files saved:\")\n",
    "    print(f\"  â€¢ {age_path}\")\n",
    "    print(f\"  â€¢ {age_nonblank_path}\")\n",
    "    print(f\"  â€¢ {counts_path}\")\n",
    "    print(f\"  â€¢ {bike_locations_path}\")\n",
    "    \n",
    "    print(f\"\\n Summary Statistics:\")\n",
    "    print(f\"  â€¢ Total non-driver age records: {age_frequency['Frequency'].sum():,}\")\n",
    "    print(f\"  â€¢ Non-blank age records: {nonblank_age_frequency['Frequency'].sum():,}\")\n",
    "    print(f\"  â€¢ Total bicycle crash locations: {len(bike_locations):,}\")\n",
    "    \n",
    "    print(f\"\\n Yearly Bicyclist Involvement:\")\n",
    "    display(bicyclist_counts)\n",
    "    \n",
    "    print(f\"\\nðŸ‘¥ Top 10 Non-Driver Ages (Non-blank):\")\n",
    "    if not nonblank_age_frequency.empty:\n",
    "        display(nonblank_age_frequency.head(10))\n",
    "    else:\n",
    "        print(\"No non-blank age data available\")\n",
    "# Save results and display summary\n",
    "save_results_and_display_summary(age_freq, age_freq_nonblank, bike_counts, bike_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1ff20d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Bicycle Crash Locations (First 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>CollisionId</th>\n",
       "      <th>Address</th>\n",
       "      <th>PrimaryRoad</th>\n",
       "      <th>SecondaryRoad</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CrashDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>1459240</td>\n",
       "      <td>US-101 N/B (GGB EAST SIDEWALK) &amp; GGB SOUTH TOWER</td>\n",
       "      <td>US-101 N/B (GGB EAST SIDEWALK)</td>\n",
       "      <td>GGB SOUTH TOWER</td>\n",
       "      <td>37.811743</td>\n",
       "      <td>-122.477211</td>\n",
       "      <td>4/20/2021 11:41:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>1559388</td>\n",
       "      <td>US-101 N/B- GGB EAST SIDEWALK &amp; NORTH TOWER OF...</td>\n",
       "      <td>US-101 N/B- GGB EAST SIDEWALK</td>\n",
       "      <td>NORTH TOWER OF GOLDEN GATE BRIDGE</td>\n",
       "      <td>37.822990</td>\n",
       "      <td>-122.478780</td>\n",
       "      <td>8/25/2021 9:34:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>1573712</td>\n",
       "      <td>EAST PARKING LOT OF GOLDEN GATE BRIGDE &amp; LINCO...</td>\n",
       "      <td>EAST PARKING LOT OF GOLDEN GATE BRIGDE</td>\n",
       "      <td>LINCOLN BOULEVARD</td>\n",
       "      <td>37.807187</td>\n",
       "      <td>-122.474038</td>\n",
       "      <td>9/10/2021 9:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>2728135</td>\n",
       "      <td>GOETTINGEN ST &amp; DWIGHT ST</td>\n",
       "      <td>GOETTINGEN ST</td>\n",
       "      <td>DWIGHT ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/8/2021 1:56:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>2733451</td>\n",
       "      <td>CLAY ST &amp; DIVISADERO ST</td>\n",
       "      <td>CLAY ST</td>\n",
       "      <td>DIVISADERO ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/17/2021 9:35:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021</td>\n",
       "      <td>2733452</td>\n",
       "      <td>18TH ST &amp; LEXINGTON ST</td>\n",
       "      <td>18TH ST</td>\n",
       "      <td>LEXINGTON ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/16/2021 6:29:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021</td>\n",
       "      <td>2733456</td>\n",
       "      <td>LOMBARD ST &amp; THE EMBARCADERO</td>\n",
       "      <td>LOMBARD ST</td>\n",
       "      <td>THE EMBARCADERO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/9/2021 2:17:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021</td>\n",
       "      <td>2733461</td>\n",
       "      <td>BATTERY ST &amp; BUSH ST</td>\n",
       "      <td>BATTERY ST</td>\n",
       "      <td>BUSH ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/19/2021 9:30:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>2733537</td>\n",
       "      <td>LAKE ST &amp; 21ST ST</td>\n",
       "      <td>LAKE ST</td>\n",
       "      <td>21ST ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/6/2021 9:26:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021</td>\n",
       "      <td>2733563</td>\n",
       "      <td>GEARY BL &amp; 5TH AV</td>\n",
       "      <td>GEARY BL</td>\n",
       "      <td>5TH AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/1/2021 10:29:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year CollisionId                                            Address  \\\n",
       "0  2021     1459240   US-101 N/B (GGB EAST SIDEWALK) & GGB SOUTH TOWER   \n",
       "1  2021     1559388  US-101 N/B- GGB EAST SIDEWALK & NORTH TOWER OF...   \n",
       "2  2021     1573712  EAST PARKING LOT OF GOLDEN GATE BRIGDE & LINCO...   \n",
       "3  2021     2728135                          GOETTINGEN ST & DWIGHT ST   \n",
       "4  2021     2733451                            CLAY ST & DIVISADERO ST   \n",
       "5  2021     2733452                             18TH ST & LEXINGTON ST   \n",
       "6  2021     2733456                       LOMBARD ST & THE EMBARCADERO   \n",
       "7  2021     2733461                               BATTERY ST & BUSH ST   \n",
       "8  2021     2733537                                  LAKE ST & 21ST ST   \n",
       "9  2021     2733563                                  GEARY BL & 5TH AV   \n",
       "\n",
       "                              PrimaryRoad                      SecondaryRoad  \\\n",
       "0          US-101 N/B (GGB EAST SIDEWALK)                    GGB SOUTH TOWER   \n",
       "1           US-101 N/B- GGB EAST SIDEWALK  NORTH TOWER OF GOLDEN GATE BRIDGE   \n",
       "2  EAST PARKING LOT OF GOLDEN GATE BRIGDE                  LINCOLN BOULEVARD   \n",
       "3                           GOETTINGEN ST                          DWIGHT ST   \n",
       "4                                 CLAY ST                      DIVISADERO ST   \n",
       "5                                 18TH ST                       LEXINGTON ST   \n",
       "6                              LOMBARD ST                    THE EMBARCADERO   \n",
       "7                              BATTERY ST                            BUSH ST   \n",
       "8                                 LAKE ST                            21ST ST   \n",
       "9                                GEARY BL                             5TH AV   \n",
       "\n",
       "    Latitude   Longitude          CrashDateTime  \n",
       "0  37.811743 -122.477211  4/20/2021 11:41:00 AM  \n",
       "1  37.822990 -122.478780   8/25/2021 9:34:00 AM  \n",
       "2  37.807187 -122.474038   9/10/2021 9:00:00 AM  \n",
       "3        NaN         NaN    3/8/2021 1:56:00 PM  \n",
       "4        NaN         NaN   1/17/2021 9:35:00 AM  \n",
       "5        NaN         NaN   1/16/2021 6:29:00 PM  \n",
       "6        NaN         NaN    1/9/2021 2:17:00 PM  \n",
       "7        NaN         NaN   1/19/2021 9:30:00 AM  \n",
       "8        NaN         NaN    1/6/2021 9:26:00 AM  \n",
       "9        NaN         NaN   2/1/2021 10:29:00 AM  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sample Age Frequency Data (First 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StatedAge</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StatedAge  Frequency\n",
       "0        11          1\n",
       "1        12          2\n",
       "2        18          1\n",
       "3        19          1\n",
       "4        20          2\n",
       "5        22          2\n",
       "6        24          1\n",
       "7        25          7\n",
       "8        26          5\n",
       "9        27          2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Complete! All results have been saved to the 'analysis_outputs' directory.\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Bicycle Crash Locations (First 10):\")\n",
    "if not bike_locations.empty:\n",
    "    display(bike_locations.head(10))\n",
    "else:\n",
    "    print(\"No bicycle crash location data available\")\n",
    "print(f\"\\n Sample Age Frequency Data (First 10):\")\n",
    "if not age_freq.empty:\n",
    "    display(age_freq.head(10))\n",
    "else:\n",
    "    print(\"No age frequency data available\")\n",
    "print(\"\\nAnalysis Complete! All results have been saved to the 'analysis_outputs' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e64a57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.10.8)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/python/3.12.1/lib/python3.12/site-packages (8.1.8)\n",
      "Requirement already satisfied: pandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (12.1.1)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (9.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# VISUALIZATIONS\n",
    "\n",
    "!pip install matplotlib ipywidgets pandas numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, Dropdown\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7a13582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary files already present\n",
      "Data loaded successfully:\n",
      " - /workspaces/crash-data/analysis_outputs/pedestrian_crash_summary_table.csv\n",
      " - /workspaces/crash-data/analysis_outputs/pedestrian_crash_summary_table_by_year.csv\n"
     ]
    }
   ],
   "source": [
    "# Autoâ€‘check and rebuild pedestrian summary files if missing\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# Reuse your existing OUTPUT_DIR variable from previous cells\n",
    "summary_path = OUTPUT_DIR / \"pedestrian_crash_summary_table.csv\"\n",
    "summary_by_year_path = OUTPUT_DIR / \"pedestrian_crash_summary_table_by_year.csv\"\n",
    "if not summary_path.exists() or not summary_by_year_path.exists():\n",
    "    print(\"Summary files missing â€“ rebuilding them using main() ...\")\n",
    "    # Call the pedestrian analysis you already defined\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"âŒ Could not regenerate summary files\") from e\n",
    "else:\n",
    "    print(\"Summary files already present\")\n",
    "# Now load them safely\n",
    "summary_all = pd.read_csv(summary_path)\n",
    "summary_by_year = pd.read_csv(summary_by_year_path)\n",
    "print(\"Data loaded successfully:\")\n",
    "print(f\" - {summary_path}\")\n",
    "print(f\" - {summary_by_year_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a719374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded:\n",
      " - Overall summary rows: 52\n",
      " - Year-by-year summary rows: 5\n"
     ]
    }
   ],
   "source": [
    "# Load already-generated summary tables\n",
    "OUT_DIR = OUTPUT_DIR  # Reuse from earlier notebook section\n",
    "summary_by_year_path = OUT_DIR / \"pedestrian_crash_summary_table_by_year.csv\"\n",
    "summary_path = OUT_DIR / \"pedestrian_crash_summary_table.csv\"\n",
    "summary_all = pd.read_csv(summary_path)\n",
    "summary_by_year = pd.read_csv(summary_by_year_path)\n",
    "print(\"âœ… Data loaded:\")\n",
    "print(f\" - Overall summary rows: {len(summary_all):,}\")\n",
    "print(f\" - Year-by-year summary rows: {len(summary_by_year):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "624d7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "AGE_ORDER = [\"0-17\", \"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65+\", \"Unknown\"]\n",
    "SEX_ORDER = [\"Female\", \"Male\", \"Non-binary\", \"Unknown\"]\n",
    "SEVERITY_ORDER = [\n",
    "    \"Fatal\",\n",
    "    \"SuspectSerious\",\n",
    "    \"SevereInactive\",\n",
    "    \"SuspectMinor\",\n",
    "    \"PossibleInjury\",\n",
    "    \"ComplaintOfPainInactive\",\n",
    "    \"OtherVisibleInactive\",\n",
    "    \"Unknown\",\n",
    "]\n",
    "def make_pivot_plot(df, title, chart_type=\"Count\"):\n",
    "    \"\"\"Create either a count or percent stacked bar chart of crash severity mix.\"\"\"\n",
    "    if df.empty:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(0.5, 0.5, \"âš ï¸ No data for this selection\", ha=\"center\", va=\"center\", fontsize=14)\n",
    "        plt.show()\n",
    "        return\n",
    "    df[\"age_group\"] = pd.Categorical(df[\"age_group\"], categories=AGE_ORDER, ordered=True)\n",
    "    df[\"sex\"] = pd.Categorical(df[\"sex\"], categories=SEX_ORDER, ordered=True)\n",
    "    pivot = (\n",
    "        df.pivot_table(\n",
    "            index=[\"age_group\", \"sex\"],\n",
    "            columns=\"severity\",\n",
    "            values=\"crash_count\",\n",
    "            aggfunc=\"sum\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "        .reindex(columns=[c for c in SEVERITY_ORDER if c in df[\"severity\"].unique()])\n",
    "        .sort_index()\n",
    "    )\n",
    "    # Normalize to percent if selected\n",
    "    if chart_type.lower() == \"percent\":\n",
    "        pivot = pivot.div(pivot.sum(axis=1).replace(0, np.nan), axis=0) * 100\n",
    "        ylabel = \"Percent of Crashes\"\n",
    "    else:\n",
    "        ylabel = \"Crash Count\"\n",
    "    pivot.plot(kind=\"bar\", stacked=True, figsize=(14, 6), width=0.85, alpha=0.9)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Age Group | Sex\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.legend(title=\"Severity\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f41296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_for_year(year_value: str) -> pd.DataFrame:\n",
    "    \"\"\"Filter summary by selected year or return all years.\"\"\"\n",
    "    if year_value == \"All Years\":\n",
    "        return summary_all.copy()\n",
    "    return summary_by_year.loc[\n",
    "        summary_by_year[\"source_year\"].astype(str) == year_value\n",
    "    ].copy()\n",
    "@interact(\n",
    "    year=Dropdown(\n",
    "        options=[\"All Years\"] + [str(y) for y in sorted(summary_by_year[\"source_year\"].astype(int).unique())],\n",
    "        value=\"All Years\",\n",
    "        description=\"Year:\",\n",
    "    ),\n",
    "    chart_type=Dropdown(\n",
    "        options=[\"Count\", \"Percent\"],\n",
    "        value=\"Count\",\n",
    "        description=\"Chart Type:\",\n",
    "    ),\n",
    ")\n",
    "def interactive_sf_plot(year, chart_type):\n",
    "    df = get_summary_for_year(year)\n",
    "    make_pivot_plot(df, f\"San Francisco Pedestrian Crashes ({year})\", chart_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
